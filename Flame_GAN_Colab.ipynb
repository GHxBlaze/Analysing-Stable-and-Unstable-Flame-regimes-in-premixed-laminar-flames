{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2dc28c98",
   "metadata": {},
   "source": [
    "# Flame Regime GAN Model\n",
    "## Generating Oscillatory Flame Behavior with Deep Learning\n",
    "\n",
    "A Generative Adversarial Network that creates realistic oscillatory flame sequences based on combustion parameters (φ - equivalence ratio, u - velocity).\n",
    "\n",
    "### Key Features:\n",
    "- **Oscillatory Patterns**: Realistic flame oscillations with physics-based dynamics\n",
    "- **Conditional Generation**: Parameter-controlled output (φ, u)\n",
    "- **LSTM Architecture**: Temporal sequence modeling\n",
    "- **Cloud Ready**: Optimized for Google Colab GPU/CPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d542b71",
   "metadata": {},
   "source": [
    "## 1. Setup and Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4fdc66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install torch matplotlib seaborn pandas numpy scikit-learn tqdm scipy -q\n",
    "\n",
    "# Mount Google Drive (optional - for loading your own data)\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)\n",
    "\n",
    "print(\"Setup completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30866cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import re, os, pickle\n",
    "from tqdm import tqdm\n",
    "from typing import Tuple, List, Dict, Optional\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.style.use('seaborn-v0_8')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90fbf7d7",
   "metadata": {},
   "source": [
    "## 2. Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c015f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the FlameGAN model code here\n",
    "# (The complete code from flame_gan_colab.py would go here)\n",
    "\n",
    "# For demonstration, I'll include a simplified version:\n",
    "exec(open('/content/flame_gan_colab.py').read()) if os.path.exists('/content/flame_gan_colab.py') else print(\"Please upload flame_gan_colab.py to Colab\")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class FlameDataset(Dataset):\n",
    "    def __init__(self, sequences, conditions):\n",
    "        self.sequences = torch.FloatTensor(sequences)\n",
    "        self.conditions = torch.FloatTensor(conditions)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.sequences[idx], self.conditions[idx]\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, noise_dim=128, condition_dim=2, sequence_length=51, output_dim=3):\n",
    "        super().__init__()\n",
    "        self.sequence_length = sequence_length\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(noise_dim + condition_dim, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(512, 768),\n",
    "            nn.BatchNorm1d(768),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2)\n",
    "        )\n",
    "        \n",
    "        self.lstm = nn.LSTM(768, 384, num_layers=3, batch_first=True, dropout=0.2)\n",
    "        self.output = nn.Sequential(\n",
    "            nn.Linear(384, 192),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(192, output_dim),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "    def forward(self, noise, conditions):\n",
    "        x = torch.cat([noise, conditions], dim=1)\n",
    "        x = self.fc(x)\n",
    "        x = x.unsqueeze(1).repeat(1, self.sequence_length, 1)\n",
    "        x, _ = self.lstm(x)\n",
    "        return self.output(x)\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, sequence_length=51, input_dim=3, condition_dim=2):\n",
    "        super().__init__()\n",
    "        self.sequence_length = sequence_length\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_dim + condition_dim, 256, num_layers=2, batch_first=True, dropout=0.3)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(256, 128),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(64, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, sequences, conditions):\n",
    "        conditions_expanded = conditions.unsqueeze(1).repeat(1, self.sequence_length, 1)\n",
    "        x = torch.cat([sequences, conditions_expanded], dim=2)\n",
    "        _, (hidden, _) = self.lstm(x)\n",
    "        return self.classifier(hidden[-1])\n",
    "\n",
    "class FlameGAN:\n",
    "    def __init__(self, device=device):\n",
    "        self.device = device\n",
    "        self.noise_dim = 128\n",
    "        self.condition_dim = 2\n",
    "        self.sequence_length = 51\n",
    "        self.output_dim = 3\n",
    "        \n",
    "        self.generator = Generator(self.noise_dim, self.condition_dim, self.sequence_length, self.output_dim).to(device)\n",
    "        self.discriminator = Discriminator(self.sequence_length, self.output_dim, self.condition_dim).to(device)\n",
    "        \n",
    "        self.g_optimizer = optim.Adam(self.generator.parameters(), lr=0.0001, betas=(0.5, 0.999), weight_decay=1e-5)\n",
    "        self.d_optimizer = optim.Adam(self.discriminator.parameters(), lr=0.0001, betas=(0.5, 0.999), weight_decay=1e-5)\n",
    "        \n",
    "        self.criterion = nn.BCELoss()\n",
    "        self.sequence_scaler = MinMaxScaler(feature_range=(-0.9, 0.9))\n",
    "        self.condition_scaler = StandardScaler()\n",
    "        self.training_history = {'g_losses': [], 'd_losses': [], 'epochs': []}\n",
    "        \n",
    "    def create_oscillatory_data(self, n_samples=300):\n",
    "        sequences = []\n",
    "        conditions = []\n",
    "        \n",
    "        for _ in range(n_samples):\n",
    "            phi = np.random.uniform(0.8, 1.2)\n",
    "            u = np.random.uniform(0.2, 0.7)\n",
    "            \n",
    "            t = np.linspace(0, 10, self.sequence_length)\n",
    "            \n",
    "            # Enhanced oscillatory patterns based on regime\n",
    "            if phi < 0.9 or (phi >= 1.0 and u < 0.3):  # Stable\n",
    "                freq_base = 0.8 + 0.4 * phi\n",
    "                amp_base = 0.3 + 0.2 * u\n",
    "                noise_level = 0.05\n",
    "            else:  # Unstable\n",
    "                freq_base = 1.2 + 0.8 * phi\n",
    "                amp_base = 0.5 + 0.4 * u\n",
    "                noise_level = 0.1\n",
    "            \n",
    "            # Generate correlated oscillatory components\n",
    "            x1 = amp_base * np.sin(freq_base * t + np.random.uniform(0, 2*np.pi))\n",
    "            x1 += 0.2 * amp_base * np.sin(3 * freq_base * t) + noise_level * np.random.randn(len(t))\n",
    "            \n",
    "            x2 = 0.8 * amp_base * np.sin(freq_base * t + np.pi/3)\n",
    "            x2 += 0.15 * amp_base * np.sin(2 * freq_base * t) + noise_level * np.random.randn(len(t))\n",
    "            \n",
    "            x3 = 0.6 * amp_base * np.sin(freq_base * t - np.pi/4)\n",
    "            x3 += 0.1 * amp_base * np.sin(1.5 * freq_base * t) + noise_level * np.random.randn(len(t))\n",
    "            \n",
    "            # Add regime-specific modulation\n",
    "            if phi >= 1.1 and u >= 0.5:  # Highly unstable\n",
    "                modulation = 0.3 * np.sin(0.2 * freq_base * t)\n",
    "                x1 *= (1 + modulation)\n",
    "                x2 *= (1 + 0.8 * modulation)\n",
    "                x3 *= (1 + 0.6 * modulation)\n",
    "            \n",
    "            sequence = np.column_stack([x1, x2, x3])\n",
    "            sequences.append(sequence)\n",
    "            conditions.append([phi, u])\n",
    "        \n",
    "        sequences = np.array(sequences)\n",
    "        conditions = np.array(conditions)\n",
    "        \n",
    "        # Normalize data\n",
    "        seq_shape = sequences.shape\n",
    "        sequences_reshaped = sequences.reshape(-1, seq_shape[-1])\n",
    "        sequences_normalized = self.sequence_scaler.fit_transform(sequences_reshaped)\n",
    "        sequences = sequences_normalized.reshape(seq_shape)\n",
    "        \n",
    "        conditions = self.condition_scaler.fit_transform(conditions)\n",
    "        \n",
    "        return sequences, conditions\n",
    "    \n",
    "    def train(self, sequences, conditions, epochs=200, batch_size=32, save_interval=50):\n",
    "        dataset = FlameDataset(sequences, conditions)\n",
    "        dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "        \n",
    "        print(f\"Training for {epochs} epochs on {len(sequences)} samples\")\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            g_losses, d_losses = [], []\n",
    "            \n",
    "            for real_sequences, real_conditions in dataloader:\n",
    "                batch_size = real_sequences.size(0)\n",
    "                real_sequences = real_sequences.to(self.device)\n",
    "                real_conditions = real_conditions.to(self.device)\n",
    "                \n",
    "                # Train Discriminator\n",
    "                self.d_optimizer.zero_grad()\n",
    "                \n",
    "                # Real data\n",
    "                real_labels = torch.ones(batch_size, 1).to(self.device) * 0.9  # Label smoothing\n",
    "                real_output = self.discriminator(real_sequences, real_conditions)\n",
    "                d_loss_real = self.criterion(real_output, real_labels)\n",
    "                \n",
    "                # Fake data\n",
    "                noise = torch.randn(batch_size, self.noise_dim).to(self.device)\n",
    "                fake_sequences = self.generator(noise, real_conditions)\n",
    "                fake_labels = torch.zeros(batch_size, 1).to(self.device)\n",
    "                fake_output = self.discriminator(fake_sequences.detach(), real_conditions)\n",
    "                d_loss_fake = self.criterion(fake_output, fake_labels)\n",
    "                \n",
    "                d_loss = (d_loss_real + d_loss_fake) / 2\n",
    "                d_loss.backward()\n",
    "                self.d_optimizer.step()\n",
    "                \n",
    "                # Train Generator\n",
    "                self.g_optimizer.zero_grad()\n",
    "                fake_output = self.discriminator(fake_sequences, real_conditions)\n",
    "                g_loss = self.criterion(fake_output, torch.ones(batch_size, 1).to(self.device))\n",
    "                g_loss.backward()\n",
    "                self.g_optimizer.step()\n",
    "                \n",
    "                g_losses.append(g_loss.item())\n",
    "                d_losses.append(d_loss.item())\n",
    "            \n",
    "            avg_g_loss = np.mean(g_losses)\n",
    "            avg_d_loss = np.mean(d_losses)\n",
    "            \n",
    "            self.training_history['g_losses'].append(avg_g_loss)\n",
    "            self.training_history['d_losses'].append(avg_d_loss)\n",
    "            self.training_history['epochs'].append(epoch)\n",
    "            \n",
    "            if epoch % 25 == 0:\n",
    "                print(f\"Epoch [{epoch}/{epochs}] - G Loss: {avg_g_loss:.4f}, D Loss: {avg_d_loss:.4f}\")\n",
    "            \n",
    "            if epoch % save_interval == 0 and epoch > 0:\n",
    "                self.save_model(f'/content/flame_gan_epoch_{epoch}.pth')\n",
    "        \n",
    "        print(\"Training completed!\")\n",
    "    \n",
    "    def generate_sequence(self, phi, u):\n",
    "        self.generator.eval()\n",
    "        with torch.no_grad():\n",
    "            condition = self.condition_scaler.transform([[phi, u]])\n",
    "            condition_tensor = torch.FloatTensor(condition).to(self.device)\n",
    "            noise = torch.randn(1, self.noise_dim).to(self.device)\n",
    "            \n",
    "            fake_sequence = self.generator(noise, condition_tensor)\n",
    "            sequence = fake_sequence.cpu().numpy()[0]\n",
    "            \n",
    "            # Denormalize\n",
    "            sequence = self.sequence_scaler.inverse_transform(sequence)\n",
    "            \n",
    "        self.generator.train()\n",
    "        return sequence\n",
    "    \n",
    "    def save_model(self, path):\n",
    "        torch.save({\n",
    "            'generator': self.generator.state_dict(),\n",
    "            'discriminator': self.discriminator.state_dict(),\n",
    "            'g_optimizer': self.g_optimizer.state_dict(),\n",
    "            'd_optimizer': self.d_optimizer.state_dict(),\n",
    "            'sequence_scaler': self.sequence_scaler,\n",
    "            'condition_scaler': self.condition_scaler,\n",
    "            'training_history': self.training_history\n",
    "        }, path)\n",
    "    \n",
    "    def load_model(self, path):\n",
    "        checkpoint = torch.load(path, map_location=self.device)\n",
    "        self.generator.load_state_dict(checkpoint['generator'])\n",
    "        self.discriminator.load_state_dict(checkpoint['discriminator'])\n",
    "        self.g_optimizer.load_state_dict(checkpoint['g_optimizer'])\n",
    "        self.d_optimizer.load_state_dict(checkpoint['d_optimizer'])\n",
    "        self.sequence_scaler = checkpoint['sequence_scaler']\n",
    "        self.condition_scaler = checkpoint['condition_scaler']\n",
    "        self.training_history = checkpoint['training_history']\n",
    "    \n",
    "    def plot_training_history(self):\n",
    "        plt.figure(figsize=(12, 4))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(self.training_history['epochs'], self.training_history['g_losses'], label='Generator')\n",
    "        plt.plot(self.training_history['epochs'], self.training_history['d_losses'], label='Discriminator')\n",
    "        plt.title('Training Losses')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(self.training_history['epochs'][-50:], self.training_history['g_losses'][-50:], label='Generator (Last 50)')\n",
    "        plt.plot(self.training_history['epochs'][-50:], self.training_history['d_losses'][-50:], label='Discriminator (Last 50)')\n",
    "        plt.title('Recent Training Progress')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "print(\"Optimized FlameGAN model loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d00c1d",
   "metadata": {},
   "source": [
    "## 3. Quick Demo with Synthetic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5438cd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick demonstration with synthetic oscillatory data\n",
    "print(\"Creating optimized Flame GAN...\")\n",
    "gan = FlameGAN(device=device)\n",
    "\n",
    "print(\"Generating enhanced synthetic data...\")\n",
    "sequences, conditions = gan.create_oscillatory_data(n_samples=300)\n",
    "print(f\"Generated {len(sequences)} sequences with shape {sequences.shape}\")\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 8))\n",
    "for i in range(4):\n",
    "    ax = axes[i//2, i%2]\n",
    "    seq = sequences[i]\n",
    "    cond = conditions[i]\n",
    "    \n",
    "    # Denormalize for display\n",
    "    seq_display = gan.sequence_scaler.inverse_transform(seq)\n",
    "    cond_display = gan.condition_scaler.inverse_transform(cond.reshape(1, -1))[0]\n",
    "    \n",
    "    ax.plot(seq_display[:, 0], label='X1', linewidth=2, alpha=0.8)\n",
    "    ax.plot(seq_display[:, 1], label='X2', linewidth=2, alpha=0.8)\n",
    "    ax.plot(seq_display[:, 2], label='X3', linewidth=2, alpha=0.8)\n",
    "    \n",
    "    regime = \"Stable\" if cond_display[0] < 0.9 or (cond_display[0] >= 1.0 and cond_display[1] < 0.3) else \"Unstable\"\n",
    "    ax.set_title(f'{regime}: φ={cond_display[0]:.2f}, u={cond_display[1]:.2f}', fontweight='bold')\n",
    "    ax.set_xlabel('Time Step')\n",
    "    ax.set_ylabel('Amplitude')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle('Enhanced Synthetic Oscillatory Data', y=1.02, fontsize=14, fontweight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc99ebb7",
   "metadata": {},
   "source": [
    "## 4. Training the GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac4bd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training optimized GAN...\")\n",
    "gan.train(sequences, conditions, epochs=200, batch_size=32, save_interval=50)\n",
    "print(\"Training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40db362e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "gan.plot_training_history()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c5cdd3",
   "metadata": {},
   "source": [
    "## 5. Generate New Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076cc269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate sequences for different flame conditions\n",
    "test_conditions = [\n",
    "    (0.8, 0.2, \"Stable - Low φ, Low u\"),\n",
    "    (0.9, 0.35, \"Stable - Medium φ, Medium u\"),  \n",
    "    (1.0, 0.5, \"Transition\"),\n",
    "    (1.2, 0.6, \"Unstable - High φ, High u\"),\n",
    "]\n",
    "\n",
    "print(\"Generating sequences for different flame conditions...\")\n",
    "\n",
    "fig, axes = plt.subplots(len(test_conditions), 3, figsize=(16, 3*len(test_conditions)))\n",
    "colors = ['#FF6B6B', '#4ECDC4', '#45B7D1']\n",
    "components = ['X1', 'X2', 'X3']\n",
    "\n",
    "for i, (phi, u, description) in enumerate(test_conditions):\n",
    "    sequence = gan.generate_sequence(phi, u)\n",
    "    print(f\"Generated: φ={phi}, u={u}\")\n",
    "    \n",
    "    for j in range(3):\n",
    "        ax = axes[i, j] if len(test_conditions) > 1 else axes[j]\n",
    "        ax.plot(sequence[:, j], color=colors[j], linewidth=2.5, alpha=0.8)\n",
    "        ax.set_title(f'{description} - {components[j]}', fontweight='bold')\n",
    "        ax.set_xlabel('Time Step')\n",
    "        ax.set_ylabel('Amplitude')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Statistics\n",
    "        mean_val, std_val = np.mean(sequence[:, j]), np.std(sequence[:, j])\n",
    "        ax.text(0.02, 0.98, f'μ={mean_val:.3f}\\nσ={std_val:.3f}', \n",
    "               transform=ax.transAxes, verticalalignment='top',\n",
    "               bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle('Generated Oscillatory Flame Sequences', y=1.01, fontsize=16, fontweight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9df28b",
   "metadata": {},
   "source": [
    "## 6. Analysis and Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d97c156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze frequency content of generated sequences\n",
    "from scipy.fft import fft, fftfreq\n",
    "\n",
    "def analyze_frequency(sequence, sampling_rate=1.0):\n",
    "    \"\"\"Analyze frequency content of a sequence\"\"\"\n",
    "    n = len(sequence)\n",
    "    fft_vals = fft(sequence)\n",
    "    freqs = fftfreq(n, 1/sampling_rate)\n",
    "    pos_mask = freqs > 0\n",
    "    return freqs[pos_mask], np.abs(fft_vals[pos_mask])\n",
    "\n",
    "# Analyze frequency content for different regimes\n",
    "fig, axes = plt.subplots(2, 3, figsize=(16, 8))\n",
    "\n",
    "stable_seq = gan.generate_sequence(0.8, 0.3)\n",
    "unstable_seq = gan.generate_sequence(1.2, 0.6)\n",
    "\n",
    "sequences = [stable_seq, unstable_seq]\n",
    "labels = ['Stable (φ=0.8, u=0.3)', 'Unstable (φ=1.2, u=0.6)']\n",
    "components = ['X1', 'X2', 'X3']\n",
    "\n",
    "for i, (seq, label) in enumerate(zip(sequences, labels)):\n",
    "    for j, comp in enumerate(components):\n",
    "        freqs, fft_vals = analyze_frequency(seq[:, j])\n",
    "        axes[i, j].semilogy(freqs[:20], fft_vals[:20], linewidth=2.5, alpha=0.8)\n",
    "        axes[i, j].set_title(f'{label} - {comp}')\n",
    "        axes[i, j].set_xlabel('Frequency')\n",
    "        axes[i, j].set_ylabel('Magnitude (log)')\n",
    "        axes[i, j].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle('Frequency Analysis', y=1.02, fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eeffa50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase space analysis\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# Generate sequences for phase space analysis\n",
    "stable_seq = gan.generate_sequence(0.8, 0.2)\n",
    "unstable_seq = gan.generate_sequence(1.2, 0.7)\n",
    "\n",
    "phase_pairs = [(0, 1, 'X1', 'X2'), (0, 2, 'X1', 'X3'), (1, 2, 'X2', 'X3')]\n",
    "\n",
    "for i, (x_idx, y_idx, x_label, y_label) in enumerate(phase_pairs):\n",
    "    axes[i].scatter(stable_seq[:, x_idx], stable_seq[:, y_idx], \n",
    "                   alpha=0.6, s=25, label='Stable', color='blue')\n",
    "    axes[i].scatter(unstable_seq[:, x_idx], unstable_seq[:, y_idx], \n",
    "                   alpha=0.6, s=25, label='Unstable', color='red')\n",
    "    axes[i].set_xlabel(x_label)\n",
    "    axes[i].set_ylabel(y_label)\n",
    "    axes[i].set_title(f'{x_label} vs {y_label} Phase Space')\n",
    "    axes[i].legend()\n",
    "    axes[i].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle('Phase Space Analysis', y=1.02, fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda22978",
   "metadata": {},
   "source": [
    "## 7. Parameter Study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "badd69c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter sweep to study the effect of phi and u\n",
    "phi_values = np.linspace(0.8, 1.2, 5)\n",
    "u_values = np.linspace(0.2, 0.7, 4)\n",
    "\n",
    "# Create a grid to visualize parameter effects\n",
    "fig, axes = plt.subplots(len(u_values), len(phi_values), figsize=(18, 12))\n",
    "\n",
    "print(\"Parameter study in progress...\")\n",
    "\n",
    "for i, u in enumerate(u_values):\n",
    "    for j, phi in enumerate(phi_values):\n",
    "        # Generate sequence\n",
    "        sequence = gan.generate_sequence(phi, u)\n",
    "        \n",
    "        ax = axes[i, j]\n",
    "        ax.plot(sequence[:, 0], linewidth=2, color='#FF6B6B', alpha=0.8)\n",
    "        \n",
    "        # Determine regime\n",
    "        regime = \"S\" if phi < 0.9 or (phi >= 1.0 and u < 0.3) else \"U\"\n",
    "        ax.set_title(f'φ={phi:.1f}, u={u:.1f} ({regime})', fontsize=9)\n",
    "        ax.set_xlabel('Time')\n",
    "        ax.set_ylabel('X1')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Background color by regime\n",
    "        bg_color = '#e8f4fd' if regime == \"S\" else '#fde8e8'\n",
    "        ax.set_facecolor(bg_color)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle('Parameter Study: φ and u Effects on Flame Oscillations', \n",
    "             y=0.98, fontsize=14, fontweight='bold')\n",
    "plt.show()\n",
    "\n",
    "print(\"Parameter study completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a249d186",
   "metadata": {},
   "source": [
    "## 8. Save Model and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4415b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '/content/flame_gan_model.pth'\n",
    "gan.save_model(model_path)\n",
    "print(f\"Model saved: {model_path}\")\n",
    "\n",
    "try:\n",
    "    drive_path = '/content/drive/MyDrive/flame_gan_model.pth'\n",
    "    gan.save_model(drive_path)\n",
    "    print(f\"Model also saved to Drive: {drive_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"Drive save failed: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876e1c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a dataset of sequences for different conditions\n",
    "print(\"Generating export dataset...\")\n",
    "\n",
    "# Define parameter grid\n",
    "phi_grid = [0.8, 0.9, 1.0, 1.1, 1.2]\n",
    "u_grid = [0.2, 0.3, 0.4, 0.5, 0.6, 0.7]\n",
    "generated_data = []\n",
    "\n",
    "for phi in phi_grid:\n",
    "    for u in u_grid:\n",
    "        # Generate sequence\n",
    "        sequence = gan.generate_sequence(phi, u)\n",
    "        filename = f\"Phi_{phi:.1f}_u_{u:.1f}_generated.txt\".replace('.', 'p')\n",
    "        \n",
    "        # Save sequence file\n",
    "        np.savetxt(f'/content/{filename}', sequence, fmt='%.6E', delimiter='\\t')\n",
    "        \n",
    "        # Collect metadata\n",
    "        regime = 'stable' if phi < 0.9 or (phi >= 1.0 and u < 0.3) else 'unstable'\n",
    "        generated_data.append({\n",
    "            'filename': filename,\n",
    "            'phi': phi,\n",
    "            'u': u,\n",
    "            'regime': regime,\n",
    "            'x1_mean': np.mean(sequence[:, 0]),\n",
    "            'x1_std': np.std(sequence[:, 0]),\n",
    "            'x2_mean': np.mean(sequence[:, 1]),\n",
    "            'x2_std': np.std(sequence[:, 1]),\n",
    "            'x3_mean': np.mean(sequence[:, 2]),\n",
    "            'x3_std': np.std(sequence[:, 2])\n",
    "        })\n",
    "\n",
    "# Create summary dataframe\n",
    "summary_df = pd.DataFrame(generated_data)\n",
    "\n",
    "# Save summary\n",
    "summary_df.to_csv('/content/generated_sequences_summary.csv', index=False)\n",
    "\n",
    "print(f\"Generated {len(generated_data)} sequences\")\n",
    "print(\"Summary saved to generated_sequences_summary.csv\")\n",
    "\n",
    "# Display summary\n",
    "print(\"\\nDataset Summary:\")\n",
    "print(summary_df.groupby('regime').agg({\n",
    "    'x1_std': 'mean',\n",
    "    'x2_std': 'mean', \n",
    "    'x3_std': 'mean'\n",
    "}).round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363bc08b",
   "metadata": {},
   "source": [
    "## 9. Usage Guide\n",
    "\n",
    "### Quick Generation:\n",
    "```python\n",
    "# Load trained model\n",
    "gan = FlameGAN()\n",
    "gan.load_model('/content/flame_gan_model.pth')\n",
    "\n",
    "# Generate sequences\n",
    "sequence = gan.generate_sequence(phi=1.0, u=0.5)\n",
    "```\n",
    "\n",
    "### Batch Generation:\n",
    "```python\n",
    "conditions = [(0.8, 0.3), (1.0, 0.5), (1.2, 0.7)]\n",
    "for phi, u in conditions:\n",
    "    seq = gan.generate_sequence(phi, u)\n",
    "    print(f\"φ={phi}, u={u}: regime={'stable' if phi<0.9 else 'unstable'}\")\n",
    "```\n",
    "\n",
    "### Using Your Data:\n",
    "1. Upload data to Google Drive\n",
    "2. Mount Drive in cell 3\n",
    "3. Replace synthetic data with your files\n",
    "4. Retrain: `gan.train(your_sequences, your_conditions, epochs=250)`\n",
    "\n",
    "### Files Generated:\n",
    "- `flame_gan_model.pth` - Trained model\n",
    "- `Phi_*_u_*_generated.txt` - Sequence files  \n",
    "- `generated_sequences_summary.csv` - Summary statistics"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
